{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version: 4.5.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# load image test\\nimg = cv.imread(r\\'training/bedroom/0.jpg\\', flags=cv.IMREAD_UNCHANGED)\\ncv.imshow(\"Display window\", img)\\ncv.waitKey()\\ncv.destroyAllWindows()\\n\\nprint(img.shape) # (200, 267) images have different sizes \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install opencv-python\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from img_gist_feature.utils_gist import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "print(\"opencv version:\", cv.__version__ )\n",
    "\n",
    "\n",
    "'''\n",
    "# load image test\n",
    "img = cv.imread(r'training/bedroom/0.jpg', flags=cv.IMREAD_UNCHANGED)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(img.shape) # (200, 267) images have different sizes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,) (1500,)\n",
      "\n",
      "{0: 'bedroom', 1: 'coast', 2: 'forest', 3: 'highway', 4: 'industrial', 5: 'insidecity', 6: 'kitchen', 7: 'livingroom', 8: 'mountain', 9: 'office', 10: 'opencountry', 11: 'store', 12: 'street', 13: 'suburb', 14: 'tallbuilding'}\n"
     ]
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    file_name=os.listdir(path)  # get the file names of all the files\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    label_dict = {}\n",
    "    for idx,fn in enumerate(file_name): \n",
    "        label_dict[idx] = fn.lower()  # save the corresponding name of each class \n",
    "        im_dirs=path+'/'+fn\n",
    "        im_path=os.listdir(im_dirs)  # get the image names of all the images \n",
    "        for n in im_path:\n",
    "            im=cv2.imread(im_dirs+'/'+n, flags=cv.IMREAD_UNCHANGED)\n",
    "            data.append(im)\n",
    "            labels.append(idx)\n",
    "    return np.asarray(data), np.asarray(labels), label_dict\n",
    "\n",
    "training_data, training_label, label_dict = read_data(r'dataset/training')\n",
    "print(training_data.shape, training_label.shape)\n",
    "print()\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [02:29<00:00, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def gist_feature(data):\n",
    "    # generate the GIST features, every image is transformed to a vector with 512 elements\n",
    "    gist_helper = GistUtils()\n",
    "    features = []\n",
    "    for image in tqdm(data):\n",
    "        features.append(gist_helper.get_gist_vec(image, mode=\"gray\"))\n",
    "    return np.asarray(features).squeeze()\n",
    "\n",
    "training_data_gist = gist_feature(training_data)\n",
    "print(training_data_gist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.30402637 0.34632015 0.32825804 0.24799967 0.23500514] \taverage: 0.29232187271118165\n",
      "score_time : [0.12332201 0.00274587 0.00374389 0.0030005  0.00199294] \taverage: 0.026961040496826173\n",
      "test_f1_weighted : [0.50216976 0.53358042 0.54905343 0.53437037 0.49624456] \taverage: 0.523083708065992\n"
     ]
    }
   ],
   "source": [
    "# linear SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted']\n",
    "scores = cross_validate(sgd_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "\n",
    "# accuracy [0.51333333 0.54333333 0.56       0.54333333 0.48333333]\n",
    "# f1_weighted [0.50216976, 0.53358042, 0.54905343, 0.53437037, 0.49624456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.00399804 0.00300002 0.00300169 0.00400233 0.00600052] \taverage: 0.004000520706176758\n",
      "score_time : [0.12600017 0.12100029 0.12400222 0.11999488 0.12199903] \taverage: 0.12259931564331054\n",
      "test_f1_weighted : [0.42249245 0.4197886  0.42915389 0.46078416 0.41589014] \taverage: 0.4296218465347928\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted']\n",
    "scores = cross_validate(knn_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "# f1_weighted [0.42249245 0.4197886  0.42915389 0.46078416 0.41589014]\n",
    "# accuracy [0.45666667 0.45       0.46       0.48333333 0.43333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.31899977 0.31999874 0.33400083 0.34000063 0.36200023] \taverage: 0.33500003814697266\n",
      "score_time : [0.18201375 0.17495346 0.20000172 0.20899868 0.1720407 ] \taverage: 0.1876016616821289\n",
      "test_f1_weighted : [0.56240514 0.64320757 0.62095    0.63658535 0.56061762] \taverage: 0.6047531364713434\n"
     ]
    }
   ],
   "source": [
    "# SVM-RBF\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(random_state=0)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted']\n",
    "scores = cross_validate(svm_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "# f1_weighted [0.56240514 0.64320757 0.62095    0.63658535 0.56061762]\n",
    "# accuracy [0.57333333 0.64666667 0.62666667 0.63666667 0.55666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.94899726 0.84703493 0.8650322  0.8910346  0.86295891] \taverage: 0.8830115795135498\n",
      "score_time : [0.0010016  0.0010047  0.00199938 0.00100446 0.002002  ] \taverage: 0.001402425765991211\n",
      "test_f1_weighted : [0.27217444 0.29825757 0.2960041  0.33553851 0.23707538] \taverage: 0.2878100013424772\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted']\n",
    "scores = cross_validate(dt_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "\n",
    "# f1_weighted [0.27217444 0.29825757 0.2960041  0.33553851 0.23707538]\n",
    "# accuracy [0.27       0.30666667 0.3        0.33666667 0.24      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.87796021 0.848001   0.79900217 0.89397025 0.82999873] \taverage: 0.8497864723205566\n",
      "score_time : [0.00200224 0.00200224 0.00200033 0.00299382 0.00300193] \taverage: 0.002400112152099609\n",
      "test_f1_weighted : [0.27217444 0.29825757 0.2960041  0.33553851 0.23707538] \taverage: 0.2878100013424772\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, random_state=0)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted']\n",
    "scores = cross_validate(dt_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "# f1_weighted [0.45054782 0.49540636 0.54606433 0.49499881 0.45866629]\n",
    "# accuracy [0.47       0.51       0.56       0.51333333 0.47333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : [0.01400065 0.01600027 0.01399827 0.01199985 0.01399803] \taverage: 0.013999414443969727\n",
      "score_time : [0.03499961 0.03300166 0.03400159 0.03704023 0.03200221] \taverage: 0.034209060668945315\n",
      "test_f1_weighted : [0.50312962 0.52984398 0.56528844 0.54532902 0.48004291] \taverage: 0.5247267921218752\n",
      "test_accuracy : [0.51       0.53       0.57       0.55       0.47333333] \taverage: 0.5266666666666666\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['f1_weighted', 'accuracy']\n",
    "scores = cross_validate(gnb_clf, training_data_gist, training_label, scoring=scoring, cv=5, return_train_score=False)\n",
    "for key, value in scores.items():\n",
    "    print(key, \":\", value, \"\\taverage:\", value.mean())  \n",
    "# f1_weighted [0.50312962, 0.52984398, 0.56528844, 0.54532902, 0.48004291]\n",
    "# accuracy [0.51      , 0.53      , 0.57      , 0.55      , 0.47333333]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tune the best model: RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "SVC(C=5, decision_function_shape='ovo', random_state=0)\n",
      "0.644572240260597\n"
     ]
    }
   ],
   "source": [
    "# SVM-RBF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "svm_clf = SVC(random_state=0)\n",
    "\n",
    "parameters = {\n",
    "    'C': [1, 2, 5, 10],\n",
    "    'gamma':[\"scale\", \"auto\"],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}\n",
    "\n",
    "splitting_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(svm_clf, parameters, cv=splitting_strategy, scoring='f1_weighted', n_jobs=-1, verbose=4)\n",
    "grid_search.fit(training_data_gist, training_label)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid_search.best_estimator_  # best classifier from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(path):\n",
    "    data = []\n",
    "    index = []\n",
    "    image_path=os.listdir(path)\n",
    "    for image_name in image_path:\n",
    "        image = cv2.imread(path + '/'+ image_name, flags=cv.IMREAD_UNCHANGED)\n",
    "        data.append(image)\n",
    "        index.append(image_name)\n",
    "    return np.asarray(data), index\n",
    "\n",
    "test_data, test_data_index = read_test_data(r'dataset/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2985/2985 [05:29<00:00,  9.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_gist = gist_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_clf.predict(test_data_gist)\n",
    "\n",
    "# save the prediciton results\n",
    "with open(\"test.txt\",\"w\") as f:\n",
    "    for i in range(len(test_data_index)):\n",
    "        f.write(test_data_index[i] + ' ' + label_dict[pred[i]] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
